{
  "cells": [
    {
      "metadata": {
        "_uuid": "b65aa0f2fc9fc43db705248455be4be27c5af028"
      },
      "cell_type": "markdown",
      "source": "# Deep Learning - Images\n<hr>\nVersion Date: 11-09-2018\n<hr>\n\n## Table of Contents\n\n1. **Image pre-processing**  \n   1.1. File directory processing  \n   1.2. Extract labels  \n   1.3. Preliminary margin trim function  \n   1.4. Trim whitespace function  \n   1.5. Resize function  \n   1.6. Color transformation function  \n   1.7. Histogram equalizer function  \n   1.8. Open images function  \n   1.9. Open images  \n   1.10.  Visualization  \n   \n2. **Data pre-processing**  \n   2.1. Class imbalance analysis  \n   2.2. Transform into numpy array  \n   2.2. Normalize  \n   2.3. One hot encoding of labels  \n   2.4. Split into trainset, valset and testset  \n   \n3. **CNN**  \n   3.1. Define model architecture  \n   3.2. Compile the model  \n   3.3. Set other parameters  \n   3.4. Train the model  \n   \n4. **Visualizations and prediction**  \n   4.1. Visualize metrics  \n   4.2. Visualize confusion matrix  \n   4.3. Prediction scores of the test set\n   \n5. **Fit the model with all the data**  \n   5.1. Fit all data  \n   5.2. Visualize all data  \n   5.3. Predict with all data  "
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c6a499843b3ca8819704fa33b8fa65dc2e883c9f"
      },
      "cell_type": "markdown",
      "source": "# 1. **Image pre-processing**\n\n## 1.1. File directory processing\n\n* declare root paths\n* no extra files in folders\n"
    },
    {
      "metadata": {
        "_uuid": "0738d76a3e4432f505d342afc63d18934e2df538",
        "trusted": true
      },
      "cell_type": "code",
      "source": "root = \"../input/flowers-recognition/flowers/flowers\"\nos.listdir(root)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b1394674d37b82c5d39b9806c303df98bc7e2030",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# delete extra files\nclasses = os.listdir(root)\nextra_ext = \".ini\"\nspecial_ext =  \".db\"\n\nfor el in classes:\n    if el.endswith(extra_ext):\n        classes.remove(el)\n        os.remove(el)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c2a3f125029d50fbaf011d4ded9e8364b69f81a0"
      },
      "cell_type": "markdown",
      "source": "## 1.2. Extract labels"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "nclasses = len(classes)\nclasses = [x.lower() for x in classes]\n\n# check duplicates in labels\nif len(classes) != len(list(set(classes))):\n    print(\"Directory pre-processing error. There are duplicates in the labels.\\n\")\n    exit(0)\n\nclasses = sorted(classes)\nclasses",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c4d170d26441bd3c73a6689bf68609cffe0564b9"
      },
      "cell_type": "markdown",
      "source": "Clean up extra files in label sub-directories"
    },
    {
      "metadata": {
        "_uuid": "4ec7d6b5805b5b7941ad8e9d02ce089639ce5b5d",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "for cl in classes:\n    clsdir = os.path.join(root, cl)\n    images = os.listdir(clsdir)\n    for img in images:\n        if img.endswith(extra_ext):\n            images.remove(img)\n            os.remove(os.path.join(clsdir, img))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "070f3566df3d6ca2f9cdf88bcab7b252289f7027"
      },
      "cell_type": "markdown",
      "source": "## 1.3. Preliminary margin trim function\n\nSome images have a border at the edges, so this function deletes this outer border. The default limit is 100px."
    },
    {
      "metadata": {
        "_uuid": "45da4c430a305d938f688150292d28f60f359013",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def trim_margin(img, lim):\n    return img[lim:-lim, lim:-lim]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5ed87a31677fdb69ad05e1e665d2fa55cda318c1"
      },
      "cell_type": "markdown",
      "source": "## 1.4. Trim whitespace function\n\nThis functions deletes the extra whitespace found sometimes in images, where the object is small and centered and there is a much bigger space of whitespace surrounding it. This function deletes the whitespace until an object is found. The input image is expected to be in BGR format.\n\nReferences:\n\n* [Trim whitespace of binarized images][1]\n* [Trim whitespace in general][2]\n  \n\n[1]: https://codereview.stackexchange.com/questions/132914/crop-black-border-of-image-using-numpy\n[2]: https://stackoverflow.com/questions/49907382/how-to-remove-whitespace-from-an-image-in-opencv"
    },
    {
      "metadata": {
        "_uuid": "5ef83de1dd2c25eebfc76ccaa1e6f18d479ff011",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def trim_whitespace(img):\n    \n    gray = cvtColor(img, cv2.COLOR_BGR2GRAY)\n    gray = 255*(gray < 128).astype(np.uint8) # To invert the img to white\n    coords = cv2.findNonZero(gray) # Find all non-zero points (text)\n    x, y, w, h = cv2.boundingRect(coords) # Find minimum spanning bounding box\n    _img = img[y:y+h, x:x+w] # Crop the original image depending on thresholds\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n    return _img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d5e1342e653673256dcff8d2e30df238f0636025"
      },
      "cell_type": "markdown",
      "source": "##  1.5. Resize image function\n\nThis function resizes the image to a supported dimension. Currently supported:\n\n* 16, 16\n* 32, 32\n* 64, 64\n* 128, 128"
    },
    {
      "metadata": {
        "_uuid": "e92a4646725d22371d74944d7f42b7a3f298d4bb",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "supported_dims = [16, 32, 64, 128]\ndef img_resize(img, dims):\n    if dims in supported_dims:\n        return cv2.resize(img, (dims, dims))\n    else:\n        print(\"Incorrect image dimensions.\\n\")\n        return None",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f37f8b5e2f5fbdee7ee738ce6cf6cdc0a3273d54"
      },
      "cell_type": "markdown",
      "source": "## 1.6. Histogram equalizer function\n\nThis function equalizes the histogram of the image (in RGB) to improve contrast."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "dcbe1d06a03681c46ae98694035b077646b3fcb1"
      },
      "cell_type": "code",
      "source": "import cv2\nfrom cv2 import imread, cvtColor, resize, threshold, calcHist, equalizeHist",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "32f60b0aa41a4d81b7fe86d6d684fed00309b775",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def equalize_hist(img):\n    img_yuv = cvtColor(img, cv2.COLOR_RGB2YUV)\n\n    # equalize the histogram of the Y channel\n    img_yuv[:,:,0] = equalizeHist(img_yuv[:,:,0])\n\n    # convert the YUV image back to RGB format\n    imgo = cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n\n    return imgo",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa6f4b9b0803179174aa7eb4696617a587aec94e"
      },
      "cell_type": "markdown",
      "source": "## 1.7. Color transformation function\n\nThe format of the images is transformed to RGB, grayscale or binarized depending on their characterstics."
    },
    {
      "metadata": {
        "_uuid": "25944b8caedb0d49b37b9dbd099e6557dd158cb1",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "color = ('r','g','b')\ndef check_grayscale(img):\n    '''\n    This function returns True if the image is grayscale, False if not.\n    The way to calculate that is to see if the 3 colors have the same pixel distribution.\n    '''\n    if img.shape[2] is 1:\n        return True\n    hists = []\n    for i,col in enumerate(color):\n        histr = calcHist([img],[i],None,[256],[0,256])\n        hists.append(histr.tolist())\n\n    return hists[1:] == hists[:-1] # https://stackoverflow.com/a/3844832/4569908",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7fb14b8e9609a3cf948f70170c76bd4b05b40af8",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def binarize(img):\n    '''\n    This function decides if the image will be binarized or not\n    '''\n    hist = cv2.calcHist([img],[0],None,[256],[0,256])\n    \n    top_limit = 5\n    binarize_limit = 32\n    black = sum(hist[top_limit:binarize_limit])\n    white = sum(hist[-binarize_limit:-top_limit])\n    total_pix = img.shape[0] * img.shape[1]\n    \n    binarize_thres = 0.4\n    if (black/total_pix > binarize_thres and white/total_pix > binarize_thres):\n        return True\n    \n    return False",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d9de3dea9cd6a74a4e6f7dff88b117ab5ef52ae4"
      },
      "cell_type": "markdown",
      "source": "### 1.7.1. Decide color format for dataset\n\nThe following code will analyze 5 images per class, decide for each image its color format, and later based on some calculations decide the final color format for the dataset"
    },
    {
      "metadata": {
        "_uuid": "51bdc35ddc72722ff680bdec475391d9a52e37a9",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def decide_color_format(img):\n    if img.shape[2] is 3 and not check_grayscale(img): # img is in RGB mode\n        return 0\n    if binarize(img): # img can be binarized\n        return 2\n    return 1 # img is not RGB and cannot be binaized --> grayscale",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9835bec002a6cbc15a9d0756d398375d52f01742",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import random\n\ndef color_code_dataset(path, dim=32):\n    img_per_class = 5\n    colors = []\n    for cl in classes:\n        clsdir = os.path.join(root, cl)\n        i = 0\n        img_in_class = os.listdir(clsdir)\n        random_imgs = random.sample(range(len(img_in_class)), img_per_class)\n        i = 0\n        for i in range(len(random_imgs)):\n            imgpath = img_in_class[random_imgs[i]]\n            if imgpath.endswith(\".db\") or imgpath.endswith(\".pyc\"):\n                continue\n            totalimgpath = os.path.join(clsdir, imgpath)\n\n            img = imread(totalimgpath, cv2.IMREAD_COLOR)\n            img = trim_margin(img, int(img.shape[0] * 0.05))\n            img = trim_whitespace(img)\n            img = img_resize(img, dim)\n            img = equalize_hist(img)\n            colors.append(decide_color_format(img))\n\n    total_sample_img = nclasses * img_per_class\n    if colors.count(0)/total_sample_img > 0.8:\n        return 0 #rgb\n    if colors.count(2)/total_sample_img > 0.8:\n        return 2 #binary\n    return 1 #grayscale",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e0c73adab63ffaa8fb0d7f58155ef80b871a07f4"
      },
      "cell_type": "markdown",
      "source": "### 1.7.2. Transform image\n\nThis function transforms the image into the color code determined before"
    },
    {
      "metadata": {
        "_uuid": "542f3933d00f49ca615fc6ee92e3029654f63a82",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def transform_color(img, color_code, dim):\n    '''\n    This function transforms the image into RGB, grayscale or binary \n    depending on the choice of the color format decided earlier.\n    '''\n    \n    if color_code is 0:\n        return cvtColor(img, cv2.COLOR_BGR2RGB) # return rgb image\n    \n    if color_code is 1:\n        return cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(dim, dim, 1)\n    \n    if color_code is 2:\n        img = cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(dim, dim, 1)\n        (_, _img) = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n        _img = 255*(_img < 128).astype(np.uint8) # To invert the text to white\n        return _img # returns binarized image\n    \n    return img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-output": false,
        "_uuid": "19a3f1797a0a5373ad3bf8689a13fb9fb6a60f61"
      },
      "cell_type": "markdown",
      "source": "## 1.8. Open images function"
    },
    {
      "metadata": {
        "_uuid": "da52655dcc5c0e89a1f17440455548cc85b1eb05",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "other_extensions = [\".db\", \".pyc\", \".py\"]\ndef open_images(path, classes, color_code, dim=32):\n    \n    xall = []\n    yall = []\n    label = 0\n    j = 0\n\n    for cl in classes:\n        clsdir = os.path.join(path, cl)\n        for imgname in os.listdir(clsdir):\n            bad_ext_found = 0\n            for other_ext in other_extensions:\n                if imgname.endswith(other_ext):\n                    bad_ext_found = 1\n                    break\n            if not bad_ext_found:\n                print(\"Opening files in {}: {}\".format(cl, str(j + 1)), end=\"\\r\")\n                imgpath = os.path.join(clsdir, imgname)\n\n                #open and pre-process images\n                img = imread(imgpath, cv2.IMREAD_COLOR)\n                img = trim_margin(img, int(img.shape[0] * 0.05))\n                img_no_trim = img\n                img = trim_whitespace(img)\n                if img.shape[0] < dim or img.shape[1] < dim:\n                    img = img_no_trim\n                img = img_resize(img, dim)\n                img = equalize_hist(img)\n                img = transform_color(img, color_code, dim)\n\n                xall.append(img)  # Get image \n                yall.append(label)  # Get image label (folder name)\n                j += 1\n\n        j = 0\n        label += 1\n        print()\n\n    n = len(xall)\n    print(\"{} images in set\".format(n))\n    return xall, yall",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa0b1956e76cc500287597e94d519ea7bec00348"
      },
      "cell_type": "markdown",
      "source": "## 1.9. Open images"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4db10b7e6a9a6448f33b7339b4fb3d0791e3326"
      },
      "cell_type": "code",
      "source": "# set parameters\ndim = 32\ncolor_code = color_code_dataset(root, dim)\nnchannels = 3\nif color_code > 0:\n    nchannels = 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1cb7f1aa2976f5d7769a4568ebbe812c711d16b6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Opening images:\\n\")\nxall, yall = open_images(root, classes, color_code, dim)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b1a55f0a8979a7b68bf59650e5bfb409ddb191a2"
      },
      "cell_type": "markdown",
      "source": "## 1.10. Visualization"
    },
    {
      "metadata": {
        "_uuid": "69d8231bdbf56bd20198d744b3b82f52ca876f02",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4ed8ce151db4b2189a66f724af6027851cdb220f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html\n# subplot(2,3,3) = subplot(233)\n# a grid of 3x3 is created, then plots are inserted in some of these slots\n\n_xall = np.asarray(xall)\n\nif color_code > 0: # 1 channel\n    _xall = _xall.reshape(-1, dim, dim)\n\nfor i in range(0,9): # how many imgs will show from the 3x3 grid\n    plt.subplot(330 + (i+1)) # open next subplot\n    plt.imshow(_xall[i + 155], cmap=plt.get_cmap('gray'))\n    plt.title(yall[i + 155]);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7560326091603ec80425e6bb1ea13e478d5f7f2f"
      },
      "cell_type": "markdown",
      "source": "# 2. **Data pre-processing**\n\n ##   2.1. Class imbalance analysis"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d05c01bf95d781f6192a3388e5e444ffde5655be"
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nsns.set(style='white', context='notebook', palette='deep')\n\n# plot how many images there are in each class\nsns.countplot(yall)\n\n_yall = pd.Series(yall)\n\n# array with each class and its number of images\nvals_class = _yall.value_counts()\nprint(vals_class)\n\n# mean and std\ncls_mean = np.mean(vals_class)\ncls_std = np.std(vals_class,ddof=1)\n\nprint(\"The mean amount of elements per class is\", cls_mean)\nprint(\"The standard deviation in the element per class distribution is\", cls_std)\n\n# 68% - 95% - 99% rule, the 68% of the data should be cls_std away from the mean and so on\n# https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule\nmetric_opt = None\nif cls_std > cls_mean * (0.6827 / 2):\n    print(\"The standard deviation is high\")\n    metric_opt = -1\n    \n# if the data is skewed then we won't be able to use accurace as its results will be misleading and we may use F-beta score instead.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c7672c04d28ce372f31dcfa732c2d27f186b6b21"
      },
      "cell_type": "code",
      "source": "vals_class.sort_index(inplace=True)\nvals_lst = list(vals_class.values)\nminclass = vals_lst.index(min(vals_lst))\nvals_lst = sorted(vals_lst)\ninteresting_class = -1 # there is no interesting class\n\n# if there is one class with much less images than the others\nif (vals_lst[1] - vals_lst[0])/(vals_lst[-1] - vals_lst[0]) > 0.3:\n    metric_opt = 1\n    interesting_class = minclass\n    \n# which class is mostly imbalanced, -1 if none\ninteresting_class",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aab99e3069d2f27f5d18fd1b888bc7053317dc66"
      },
      "cell_type": "markdown",
      "source": "## 2.2.Transform into numpy array"
    },
    {
      "metadata": {
        "_uuid": "f914fe97890d58c492113d80cd7a0862f7a2c431",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "xall = np.asarray(xall)\nyall = np.asarray(yall)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "113a1f7ee494ab88aaa1444f1981402049eeaefc"
      },
      "cell_type": "code",
      "source": "xall.shape, yall.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ac69fdddd87c2d3f2b49599fcd6118ba1f48b450"
      },
      "cell_type": "markdown",
      "source": "##   2.2. Normalize  "
    },
    {
      "metadata": {
        "_uuid": "7748057c9ffcb385496ebbddb07ae38a9a14e572",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "xall = xall / 255",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4c4c87f991ab59a2cbe692b7794c3655a9f87c79"
      },
      "cell_type": "markdown",
      "source": "##  2.3. One hot encoding of labels  "
    },
    {
      "metadata": {
        "_uuid": "e89e5d332e589aedc66e5d3534b229e01b6db24b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.utils.np_utils import to_categorical\n\nprint(\"Shape of labels before: \", yall.shape) \nyall = to_categorical(yall, num_classes = nclasses)\nprint(\"Shape of labels after: \", yall.shape) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ce3da69558086c211dabf14fe9db44204caa403e"
      },
      "cell_type": "markdown",
      "source": "## 2.4. Split into trainset, valset and testset  "
    },
    {
      "metadata": {
        "_uuid": "e8fa5c47325f14e53af08fbca436239ff6c1d96a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\n# fix random seed for reproducibility\nseed = 35\nnp.random.seed(seed)\n\n# split xtrain/xval from testset\nsplit_pct = 0.1\n_xall, xtest, _yall, ytest = train_test_split(xall, yall, test_size=split_pct, random_state=seed, shuffle=True, stratify=yall)\n\n# split xtrain from xval\nsplit_pct = 0.2\nxtrain, xval, ytrain, yval = train_test_split(_xall, _yall, test_size=split_pct, random_state=seed, shuffle=True, stratify=_yall)\n\nprint(\"trainset:\", xtrain.shape, ytrain.shape, \"\\tvalset:\", xval.shape, yval.shape, \"\\ttestset:\", xtest.shape, ytest.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "572138390851138e14f5435e24dd4ac2a025ebca"
      },
      "cell_type": "markdown",
      "source": "# 3. **CNN**\n\n[Possible reasons why network isn't working][1]\n\n[1]: https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607"
    },
    {
      "metadata": {
        "_uuid": "396e8c6c6eedca02c0b16f47e72eb052b6eed867",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import functools\nimport tensorflow as tf\nfrom keras import backend as K\n\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPool2D, AvgPool2D\nfrom keras.regularizers import l1, l2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d016892b60f3d44dc6b02cd1b817ededabf64981"
      },
      "cell_type": "markdown",
      "source": "## 3.1. Define model architecture"
    },
    {
      "metadata": {
        "_uuid": "15757eae7dfbb6496de6cb494e5c3556b8a61e54",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def create_model(nchannels):\n\n    model = Sequential()\n\n    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(dim,dim,nchannels)))\n    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='valid', activation='relu', kernel_regularizer=l2(0.0001)))\n    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='valid', activation='relu', kernel_regularizer=l2(0.0001)))\n    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='valid', activation='relu', kernel_regularizer=l2(0.0001)))\n    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n    model.add(Dropout(0.2))    \n\n    model.add(Flatten())\n    model.add(Dense(120, activation='relu'))\n    model.add(Dense(120, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(nclasses, activation='softmax'))\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ca8cb1535645abc3516f6200ad171cd5edfd515d"
      },
      "cell_type": "markdown",
      "source": "## 3.2. Compile the model\n\nUnbalanced classes create two problems:\n\n* The accuracy (i.e. ratio of test samples for which the correct class is correctly predicted) is no longer a good measure of the model performance. A model that just predicts “not cancer” everytime will yield a 95% accuracy, even though it is a bad (and even dangerous) model that does not yield any insight or scientific advancement, despite the fact that “95% accuracy” sounds like something good. In addition, it’s hard to get an intuition for how good a model with 96%, 97% or 98% accuracy really is.\n\n* The training process might arrive at a local optimum that always predicts “not cancer”, making it hard to further improve the model.\n\nPossible solutions:\n\n* Collect more data\n* [Resample dataset][1]: \n   * oversample the under-represented class. good when dataset is small\n       * Create copies of training samples\n       * Create augmented copies of training samples\n   * undersample the over-represented class. good when dataset is big\n       * Remove training samples\n* Change performance metric\n* Train for sensitivity and specificity:\n   * *Sensitivity*: probability that we detect cancer, given that the patient really has cancer.\n   * *Specificity*: probability that we do not detect cancer, given that the patient doesn’t have cancer\n  \nOther general advice on [class imbalance][2].  \nOther [metrics][3] apart from accuracy.  \n\n[1]: https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis\n[2]: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n[3]: https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/"
    },
    {
      "metadata": {
        "_uuid": "d532766cdc071ce8619c1124a75411b60bab1de5"
      },
      "cell_type": "markdown",
      "source": "   ### 3.2.1. Option 1: \n \n This [option][1] changes the metric to sensitivity and specificity.\n \n[1]: http://www.deepideas.net/unbalanced-classes-machine-learning/"
    },
    {
      "metadata": {
        "_uuid": "ae65be9bbdc1456bd21d7d361821f7548140bbb3",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def single_class_accuracy(interesting_class_id):\n    def fn(y_true, y_pred):\n        class_id_true = K.argmax(y_true, axis=-1)\n        class_id_preds = K.argmax(y_pred, axis=-1)\n        # Replace class_id_preds with class_id_true for recall here\n        accuracy_mask = K.cast(K.equal(class_id_preds, interesting_class_id), 'int32')\n        class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n        class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n        return class_acc\n    return fn",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "00621086634dd9126616dace8041ff583eaa502f"
      },
      "cell_type": "markdown",
      "source": "   ### 3.2.2. Option 2: \n \n This [option][1] implements the metrics fmeasure, precision, and recall which were not included in Keras 2.0.\n \n[1]: https://github.com/keras-team/keras/issues/5400#issuecomment-314747992"
    },
    {
      "metadata": {
        "_uuid": "73ffd879dff9d37cf35c45c6d0cef45c381ccfe1",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def mcor(y_true, y_pred):\n    #matthews_correlation\n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n    y_pred_neg = 1 - y_pred_pos\n    \n    y_pos = K.round(K.clip(y_true, 0, 1))\n    y_neg = 1 - y_pos\n\n    tp = K.sum(y_pos * y_pred_pos)\n    tn = K.sum(y_neg * y_pred_neg)\n\n    fp = K.sum(y_neg * y_pred_pos)\n    fn = K.sum(y_pos * y_pred_neg)\n\n    numerator = (tp * tn - fp * fn)\n    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n\n    return numerator / (denominator + K.epsilon())\n\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n\n    Only computes a batch-wise average of precision.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef recall(y_true, y_pred):\n    \"\"\"Recall metric.\n\n    Only computes a batch-wise average of recall.\n    Computes the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef f1(y_true, y_pred):\n    \n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n    \n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "34de9d1248b813a80d4bb7b8ad8996cf76c7bb32"
      },
      "cell_type": "markdown",
      "source": "   ### 3.2.3. Option 3:\n \n This [option][1] implements the metrics precision, and recall obtained directly from tensorflow.\n \n[1]: https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras/50566908#50566908"
    },
    {
      "metadata": {
        "_uuid": "ee5c5ff19a6badc86ed48d37c51c6838b882114f",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def as_keras_metric(method):\n    @functools.wraps(method)\n    def wrapper(self, args, **kwargs):\n        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n        value, update_op = method(self, args, **kwargs)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([update_op]):\n            value = tf.identity(value)\n        return value\n    return wrapper",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4525fecb63053117c5c238638b1a41960df1a68d"
      },
      "cell_type": "markdown",
      "source": "### 3.2.4. Compile the model"
    },
    {
      "metadata": {
        "_uuid": "892887a045940b986673a26f82eff3eeafeca851",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def compile_model(model, optimizer=\"adam\", loss=\"categorical_crossentropy\", metric_opt=0, interesting_class=0):\n    \n    if metric_opt == 0:\n        metric = [\"accuracy\"]\n    if metric_opt == 1:\n        metric = [single_class_accuracy(interesting_class)]\n    elif metric_opt == 2:\n        metric = [mcor, f1, recall]\n    elif metric_opt == 3:\n        precision2 = as_keras_metric(tf.metrics.precision)\n        recall2 = as_keras_metric(tf.metrics.recall)\n        metric = [precision2, recall2]\n        \n    model.compile(optimizer=optimizer, loss=loss, metrics=metric)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9d4f2e9ed8ad98078c3c3d0bcca5c0c6d228060",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model = create_model(nchannels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "71f929c3ca0db13d3188a2d964b0a8dd1d97b49e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "if not metric_opt:\n    metric_opt = 0\nelif metric_opt == -1: # there is class imbalance\n    metric_opt = 2\nelif metric_opt != 1: # no class imbalance, no \"interesting\" class found\n    metric_opt = 0\n    \ncompile_model(model, \"adam\", \"categorical_crossentropy\", metric_opt)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f34838f982f6e63a718950aad4beeb3742cc8956",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f87082c318c7463ef543ac592a1afdc690d2be17"
      },
      "cell_type": "markdown",
      "source": "## 3.3. Set other parameters"
    },
    {
      "metadata": {
        "_uuid": "3f4f9010cc485bf3a2c44c952cc0910feb158436",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e6855fc16104c855d534e13a6caf8d0d392cad53",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def add_data_augmn(xtrain):\n\n    datagen = ImageDataGenerator(\n            featurewise_center=False,  # set input mean to 0 over the dataset\n            samplewise_center=False,  # set each sample mean to 0\n            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n            samplewise_std_normalization=False,  # divide each input by its std\n            zca_whitening=False,  # apply ZCA whitening\n            rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n            zoom_range=0.1, # Randomly zoom image \n            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n            horizontal_flip=False,  # randomly flip images\n            vertical_flip=False)  # randomly flip images\n\n    datagen.fit(xtrain)\n    return xtrain, datagen",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "088bfc3e6d5ebe9c58e6ded21c9842767c9c70c4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "size_thres = [1000, 5000, 10000, 50000, 100000]\nbatch_sizes = [16, 32, 64, 128, 256]\nepochs_thres = [50, 40, 35, 20, 15]\ndef set_batch_epochs(nimages):\n    for i in range(len(size_thres)):\n        if nimages < size_thres[i]:\n            return epochs_thres[i], batch_sizes[i]\n    return epochs_thres[-1], batch_sizes[-1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3ef55af2b1498f2f07517c10d423335c1425bcd8",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "epochs, batch_size = set_batch_epochs(xtrain.shape[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dd13f1aab78b38aadc7daa7aede8095636f79612"
      },
      "cell_type": "markdown",
      "source": "## 3.4. Train model\n\nPossible problems:\n* Training loss doesn't decrease\n   + The batches contain a single label\n   + batch_size too big\n   + [Github answer 1][1]\n   + [Github answer 2][2]\n   + [Stackoverflow answer][3]\n   + [Stackexchange answer][4]\n   \n* Overfitting\n   + [Regularization techniques][5]\n   + Dropout\n   + Data augmentation\n   \n[1]: https://github.com/BVLC/caffe/issues/2731\n[2]: https://github.com/keras-team/keras/issues/2711\n[3]: https://stackoverflow.com/questions/38098560/increasing-training-data-doesnt-reduce-overfitting-in-cnn\n[4]: https://datascience.stackexchange.com/questions/30930/accuracy-and-loss-dont-change-in-cnn-is-it-over-fitting\n[5]: https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/"
    },
    {
      "metadata": {
        "_uuid": "e61787741cb6d49b4df4b81494a281bc2db3b3f7",
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_aug = 1\n\nif data_aug > 0:\n    xtrain, datagen = add_data_augmn(xtrain)\n    history_train = model.fit_generator(datagen.flow(xtrain,ytrain, batch_size=batch_size),\n                                  epochs=epochs, \n                                  validation_data=(xval,yval),\n                                  verbose=1, \n                                  shuffle=True, # always shuffle, in small datasets one epoch could contain just 1 label --> it doesn't learn!\n                                  callbacks=[learning_rate_reduction])\n\nelse:\n    history_train = model.fit(x=xtrain, \n                        y=ytrain, \n                        batch_size=batch_size, \n                        epochs=epochs, \n                        verbose=1, \n                        callbacks=[learning_rate_reduction],#, early_stop], \n                        validation_split=0.0, \n                        validation_data=(xval,yval), \n                        shuffle=True, \n                        class_weight=None, \n                        sample_weight=None, \n                        initial_epoch=0, \n                        steps_per_epoch=None, \n                        validation_steps=None)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "940139bc23898d65ff14c39c1300ed38a9d9ae88"
      },
      "cell_type": "markdown",
      "source": "# 4. **Visualizations and prediction**\n\n## 4.1. Visualize metrics"
    },
    {
      "metadata": {
        "_uuid": "da2f9ae006d342b7b7c3e474a054521587a0e5fc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "metrics = list(history_train.history.keys())\n\n# Plot the loss and accuracy curves for training and validation \niterations = int((len(metrics) - 1)/2)\nfig, ax = plt.subplots(iterations, 1)\n\nfor i in range(iterations):\n    ax[i].plot(history_train.history[metrics[i + iterations]], color='b', label=\"train_\" + metrics[i + iterations])\n    ax[i].plot(history_train.history[metrics[i]], color='r', label=metrics[i], axes=ax[i])\n    ax[i].grid(color='black', linestyle='-', linewidth=0.25)\n    legend = ax[i].legend(loc='best', shadow=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "356ba6ff23179b8d5673128e176e55f4bb8aa302"
      },
      "cell_type": "markdown",
      "source": "## 4.2. Visualize confusion plot"
    },
    {
      "metadata": {
        "_uuid": "96258f9cd6d8dbe8407e74ab6e51d3eb88485916",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\nimport itertools\n\n# Confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nypred = model.predict(xval)\n# Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\nypred_classes = np.argmax(ypred,axis=1)\n# Convert validation observations from one hot vectors to labels\nytrue = np.argmax(yval,axis=1)\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(ytrue, ypred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, range(nclasses), False, \"Confusion matrix of the val set\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b4bbda5fd6b34fc694b292da890280fc92b0c4a0"
      },
      "cell_type": "markdown",
      "source": "## 4.3. Prediction scores of the test set"
    },
    {
      "metadata": {
        "_uuid": "e096d4bbda98cfcab36c2edc7de98780bd2488ff",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\nxtest = xtest.reshape(-1, dim, dim, nchannels)\nypredtest = model.predict_classes(xtest)\n# Convert validation observations from one hot vectors to labels\nytrue = np.argmax(ytest,axis=1)\nprint(\"Test accuracy score:\", accuracy_score(ytrue, ypredtest))\nprint(\"Test F1 score:\", f1_score(ytrue, ypredtest, average=\"macro\"))\nprint(\"Test precision score:\", precision_score(ytrue, ypredtest, average=\"macro\"))\nprint(\"Test recall score:\", recall_score(ytrue, ypredtest, average=\"macro\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "341c623a22041994e722bfd79fbd2894a8eb32d1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Predict the values from the validation dataset\nypred = model.predict(xtest)\n# Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\nypred_classes = np.argmax(ypred,axis=1)\n# Convert validation observations from one hot vectors to labels\nytrue = np.argmax(ytest,axis=1)\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(ytrue, ypred_classes)\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, range(nclasses), False, \"Confusion matrix of the test set\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4dce7f06fd8af4e26bd048c1748e3064f4021095",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# 5. **Fit the model with all the data**\n\n## 5.1. Fit all data"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8b80c1365166cd44f768d820858d5c0ff8f0076a"
      },
      "cell_type": "code",
      "source": "model = create_model(nchannels)\ncompile_model(model, \"adam\", \"categorical_crossentropy\", metric_opt)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "adb1f1c1e579a82097a7a18d6edb6bae4e201714"
      },
      "cell_type": "code",
      "source": "learning_rate_reduction = ReduceLROnPlateau(monitor='loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "61c09288f03e55a2275304e151e0dde11c5a2e4a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "epochs, batch_size = set_batch_epochs(xall.shape[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1248ba9da339a0851ecdfe1b006bf4e03a6f40c1",
        "trusted": true,
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "xall, datagen = add_data_augmn(xall)\nhistory = model.fit_generator(datagen.flow(xall,yall, batch_size=batch_size),\n                              epochs=epochs, \n                              verbose=1, \n                              callbacks=[learning_rate_reduction])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "56d6a905c90b8bf98e30ef20422d299484f8bf66"
      },
      "cell_type": "markdown",
      "source": "## 5.2. Visualize all data"
    },
    {
      "metadata": {
        "_uuid": "d3ca02e1ef413e1eca3ff668928cfe70c8144eb8",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "metrics = list(history.history.keys())\n\nfig, ax = plt.subplots(len(metrics)-1, 1)\n\nfor i in range(len(metrics)-1):\n    ax[i].plot(history.history[metrics[i]], color='b', label=metrics[i])\n    ax[i].grid(color='black', linestyle='-', linewidth=0.25)\n    legend = ax[i].legend(loc='best', shadow=True)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0d7c274515ab066c8f6d28733495751373364abe"
      },
      "cell_type": "markdown",
      "source": "   ## 5.3. Predict with all data"
    },
    {
      "metadata": {
        "_uuid": "e17eeb3c46aae48aa9bb155c8f0652da30821b84",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "xtest = xtest.reshape(-1, dim, dim, nchannels)\nypredtest = model.predict_classes(xtest)\n# Convert validation observations from one hot vectors to labels\nytrue = np.argmax(ytest,axis=1)\nprint(\"test_acc\", accuracy_score(ytrue, ypredtest))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d3a6fbef9ab58f14c72a0323a7d75188f606d13",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Predict the values from the validation dataset\nypred = model.predict(xtest)\n# Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\nypred_classes = np.argmax(ypred,axis=1)\n# Convert validation observations from one hot vectors to labels\nytrue = np.argmax(ytest,axis=1)\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(ytrue, ypred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes=range(nclasses))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "46530c9d49eae51a749c3d0bf46bfd65717bdbbb",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}