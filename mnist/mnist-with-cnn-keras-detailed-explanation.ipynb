{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4229d26429f6fdf9dd42b26b8b02a4c4175b707"
   },
   "source": [
    "# MNIST with CNN (Keras) - Detailed explanation\n",
    "\n",
    "### **Ane Berasategi** - 25/07/2018\n",
    "\n",
    "* **0. Introduction**\n",
    "\n",
    "* **1. Data pre-processing**\n",
    "    * 1.1. Load data\n",
    "    * 1.2. Check shape, data type\n",
    "    * 1.3. Extract xtrain, ytrain\n",
    "    * 1.4. Mean and std of classes\n",
    "    * 1.5. Check nuls and missing values\n",
    "    * 1.6. Visualization\n",
    "    * 1.7. Normalization\n",
    "    * 1.8. Reshape\n",
    "    * 1.9. One hot encoding of label\n",
    "    * 1.10. Split training and validation sets  \n",
    "    \n",
    "* **2. CNN**\n",
    "    * 2.1. Define model architecture\n",
    "    * 2.2. Set optimizer and learning rate annealer\n",
    "    * 2.3. Data augmentation\n",
    "    * 2.4. Fit model\n",
    "    \n",
    "* **3. Model evaluation and plots**\n",
    "    * 3.1. Plot training loss and evaluation loss\n",
    "    * 3.2. Plot confusion matrix\n",
    "    * 3.3. Plot errors\n",
    "\n",
    "* **4. Predict and save to csv**\n",
    "    * 4.1. Predict\n",
    "    * 4.2. Save to csv\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d5780ab91c4dbd65ba303299ef03e596f55fff5c"
   },
   "source": [
    "# 0. Introduction\n",
    "\n",
    "This is my first CNN kernel and as such, I believe the [Digit Recognizer dataset/competition](https://www.kaggle.com/c/digit-recognizer) is a very suitable set of images for a beginner CNN project, considering the image size is homogeneous across all images (not common in real-world problems), that the size is small (28x28) so no resizing required, they are in grayscale and they are already in a csv, which can be easily read into a dataframe. \n",
    "\n",
    "<img src=\"http://img1.imagilive.com/0717/mnist-sample.png\" ></img>\n",
    "\n",
    "Given the comfort that this dataset provides and taking inspration from very popular kernels such as [yassineghouzam's kernel](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6) and [poonaml's kernel](https://www.kaggle.com/poonaml/deep-neural-network-keras-way) among others, I've created my own kernel joining what I have found most useful from each kernel, as well as adding what I have learnt in the process and other notes that may be helpful for others or for future me.\n",
    "\n",
    "The kernel consists in 3 main parts:\n",
    "   * Data preparation\n",
    " Firstly, even if the input data is already quite clean as mentioned before, it still needs some preparation and pre-processing in order to be in an appropriate format to then later be fed to the NN. This includes data separation, reshaping and visualization which might give insight to the data scientist as to the nature of the images.\n",
    "   * CNN\n",
    "Afterwards, the NN is defined (this is where Keras comes in), the convolutional steps added, NN parameters initialized, and the model trained. This part takes the most time in a ML project.\n",
    "   * Evaluation\n",
    "Once the model is trained, it's interesting to evaluate the model performance by seeing the progress of the loss and extract some conclusions, that the model is overfitting, or if there is high variance for instance.\n",
    "\n",
    "If you find some errors in theoretical concepts, comments of any kind or suggestions, please do let me know :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np # linear algebra, matrix multiplications\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# 1. Data pre-processing\n",
    "## 1.1 Load data\n",
    "\n",
    "   * train\n",
    "this is the data used to train the CNN.  \n",
    "the image data and their corresponding class is provided.   \n",
    "the CNN learns the weights to create the mapping from the image data to their corresponding class.  \n",
    "\n",
    "\n",
    "   * test\n",
    "this is the data used to test the CNN.  \n",
    "only the image data is provided.  \n",
    "the prediction is submitted to the competition and depending on the accuracy, a score is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "5c4c2fa7eeffa51a4c2294cac109bed54fda7dca"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-032e52796572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../input/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6dca7aa2c39302f7f2e568c01e7d44ecbf12dc1a"
   },
   "source": [
    "## 1.2. Check shape, data type\n",
    "\n",
    "   * train\n",
    "the train dataframe contains data from 42k images.  \n",
    "the data from each image is streched out in 1D with 28*28 = 784 pixels.  \n",
    "the first column is the label/class it belongs to, the digit it represents.  \n",
    "\n",
    "\n",
    "   * test\n",
    "the test dataframe contains data from 28k images.  \n",
    "this data shall be fed to the CNN so that it's new data, that the CNN has never seen before.  \n",
    "same as in the train dataset, image data is streched out in 1D with 784 pixels.  \n",
    "there is no label information, that is the goal of the competition, predicting labels as well as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a7cb2975ffe4514b061c379a9bf8cc37c48f9ed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check data\n",
    "\n",
    "print(train.shape)\n",
    "ntrain = train.shape[0]\n",
    "\n",
    "print(test.shape)\n",
    "ntest = test.shape[0]\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ffd9d5ea1aa332b428fa668215c7c84c28f3dae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check data type\n",
    "print(train.dtypes) # all int64, otherwise do train = train.astype('int64')\n",
    "\n",
    "print(train.dtypes) # all int64, otherwise do test = test.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c71f725e3a5fb0bcca79a6797f48556888797e7"
   },
   "source": [
    "## 1.2 Extract xtrain, ytrain \n",
    "The CNN will be fed xtrain and it will learn the weights to map xtrain to ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9d2f465a2abfab92687cd5c08404f7e8aef8ae6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract xtrain, ytrain\n",
    "\n",
    "# array containing labels of each image\n",
    "ytrain = train[\"label\"]\n",
    "print(\"Shape of ytrain: \", ytrain.shape)\n",
    "\n",
    "# dataframe containing all pixels (the label column is dropped)\n",
    "xtrain = train.drop(\"label\", axis=1)\n",
    "\n",
    "# the images are in square form, so dim*dim = 784\n",
    "from math import sqrt\n",
    "dim = int(sqrt(xtrain.shape[1]))\n",
    "print(\"The images are {}x{} squares.\".format(dim, dim))\n",
    "\n",
    "print(\"Shape of xtrain: \", xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e5f24bd732ba81028c32812eccec43ce50db629",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4b74cdf8150c9a6a4e6910bfa0f1441162d4f19"
   },
   "source": [
    "## 1.3. Mean and std of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6eb1fc174dc86ce277e2b8fc858ea1067c8174ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "# plot how many images there are in each class\n",
    "sns.countplot(ytrain)\n",
    "\n",
    "print(ytrain.shape)\n",
    "print(type(ytrain))\n",
    "\n",
    "# array with each class and its number of images\n",
    "vals_class = ytrain.value_counts()\n",
    "print(vals_class)\n",
    "\n",
    "# mean and std\n",
    "cls_mean = np.mean(vals_class)\n",
    "cls_std = np.std(vals_class,ddof=1)\n",
    "\n",
    "print(\"The mean amount of elements per class is\", cls_mean)\n",
    "print(\"The standard deviation in the element per class distribution is\", cls_std)\n",
    "\n",
    "# 68% - 95% - 99% rule, the 68% of the data should be cls_std away from the mean and so on\n",
    "# https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule\n",
    "if cls_std > cls_mean * (0.6827 / 2):\n",
    "    print(\"The standard deviation is high\")\n",
    "    \n",
    "# if the data is skewed then we won't be able to use accurace as its results will be misleading and we may use F-beta score instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33027153afbdb5887955c8f39e29c000e374b573"
   },
   "source": [
    "> Summary\n",
    "\n",
    "Shape of xtrain is: (42000, 784)  \n",
    "Shape of ytrain is: (42000, )  \n",
    "Shape of test is: (28000, 784)  \n",
    "\n",
    "number of classes = 10, the distribution of the pictures per class has a mean of 4200 images and a std of 237 images.     \n",
    "The digit 1 has the most representation (4684 images) and the digit 5 the least (3795 images). This data can be seen by printing *vals_class*  \n",
    "This corresponds to a small standard deviation (5.64%) so there is no class imbalance. In case there was, other techniques would have to be considered but this is outside the scope of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b07fc7612d5ce54f82d9debdce7273fd9a3f735"
   },
   "source": [
    "## 1.4. Check nuls and missing values\n",
    "```python\n",
    "df.isnull()\n",
    "```\n",
    "returns a boolean df with true if value is NaN and false otherwise.  \n",
    "```python\n",
    "df.isnull().any()\n",
    "```\n",
    "returns a df with 1 col and ncol rows where each row says if there is a NaN value present in that col.  \n",
    "```python\n",
    "df.isnull().any().any()\n",
    "```\n",
    "returns a bool with True if any of the df.isnull().any() rows is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03c7f67d1575a25008ebd244872a262f4a4495ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the data\n",
    "\n",
    "def check_nan(df):\n",
    "    print(df.isnull().any().describe())\n",
    "    print(\"There are missing values\" if df.isnull().any().any() else \"There are no missing values\")\n",
    "\n",
    "    if df.isnull().any().any():\n",
    "        print(df.isnull().sum(axis=0))\n",
    "        \n",
    "    print()\n",
    "        \n",
    "check_nan(xtrain)\n",
    "check_nan(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c960d91af825d5cf5d291ef019b779876e5ccb06"
   },
   "source": [
    "## 1.5. Visualization\n",
    "\n",
    "The first nine images in the dataset (which are not ordered by digit) are plotted, just for visualization. There is only one color channel (grayscale) and moreover the pixels are binarized, meaning that hey are either black (with value 0) or white (255). This makes the classification problem easier. Imagine that the CNN received colored digits, either solid, gradient, or digits with many colors. Probably some part of the neural network would focus on learning to tell the digits apart by looking at the colors, when the actual difference between the digits is in their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a22f34f81cb94af5787f06448e326058e61122d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# convert train dataset to (num_images, img_rows, img_cols) format in order to plot it\n",
    "xtrain_vis = xtrain.values.reshape(ntrain, dim, dim)\n",
    "\n",
    "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html\n",
    "# subplot(2,3,3) = subplot(233)\n",
    "# a grid of 3x3 is created, then plots are inserted in some of these slots\n",
    "for i in range(0,9): # how many imgs will show from the 3x3 grid\n",
    "    plt.subplot(330 + (i+1)) # open next subplot\n",
    "    plt.imshow(xtrain_vis[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(ytrain[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2051502a7a5443f14679c836f5f3bfabd8d0bdac"
   },
   "source": [
    "## 1.6. Normalization\n",
    "Pixels are represented in the range [0-255], but the NN converges faster with smaller values, in the range [0-1] so they are normalized to this range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76e6f0a067bb7cabf2cfa079a3917f2391693872",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "xtrain = xtrain / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e07e4cdd4acf0ae14bb0dcb633fd2e020ff3e3d6"
   },
   "source": [
    "## 1.7. Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9685eb7e78736876af2f032c53dd2f2d2ea5382b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape of image data to (nimg, img_rows, img_cols, 1)\n",
    "def df_reshape(df):\n",
    "    print(\"Previous shape, pixels are in 1D vector:\", df.shape)\n",
    "    df = df.values.reshape(-1, dim, dim, 1) \n",
    "    # -1 means the dimension doesn't change, so 42000 in the case of xtrain and 28000 in the case of test\n",
    "    print(\"After reshape, pixels are a 28x28x1 3D matrix:\", df.shape)\n",
    "    return df\n",
    "\n",
    "xtrain = df_reshape(xtrain) # numpy.ndarray type\n",
    "test = df_reshape(test) # numpy.ndarray type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d94d64556e53d62e3822542f4575d82f1132bd28"
   },
   "source": [
    "> Note\n",
    "\n",
    "In real world problems, the dimensions of images could diverge from this particular 28x28x3 set in two ways:\n",
    "   * Images are usually much bigger\n",
    "\n",
    "In this case all images are 28x28x1, but in another problem I'm working on, I have images of 3120x4160x3, so much bigger and in RGB. Usually images are resized to much smaller dimensions, in my case I'm resizing them to 64x64x3 but they can be made much smaller depending on the problem. In this MNIST dataset there is no such problem since the dimensions are already small.\n",
    "   * Images don't usually have the same dimensions\n",
    "   \n",
    "Different dimension images are a problem since dense layers at the end of the CNN have a fixed number of neurons, which cannot be dynamically changed. This means that the layer expects fixed image dimensions, which means all images must be resized to the same dimensions before training. There is another option, namely, using a FCN (fully convoluted network) which consits solely of convolutional layers and a very big pooling in the end, so each image can be of any size, but this architecture isn't as popular as the CNN + FC (fully connected) layers which is the one I'm familiarized with.  \n",
    "There are various methods to make images have the same dimensions:\n",
    "   * resize to a fixed dimension\n",
    "   * add padding to some images and resize\n",
    "   * ...  \n",
    "\n",
    "In my other problem I have scanned pictures, so I trim the whitespace and resize afterwards. Being this a beginner-friendly dataset, all digits are the same size, binarized and well centered so no need to worry about resizing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac10231c13c9f52440bbb76ed6bc285c402d9b5e"
   },
   "source": [
    "## 1.8. One hot encoding of label\n",
    "\n",
    "At this point in the notebook the labels vary in the range [0-9] which is intuitive, but in order to define the type of loss for the NN later, which in this case is categorical_crossentropy (reason is explained in section 2), the targets should be in categorical format (=one hot-vectors): ex : 2 -> [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "ytrain before  \n",
    "0    1  \n",
    "1    0  \n",
    "2    1  \n",
    "3    4  \n",
    "4    0  \n",
    "\n",
    "where the first column is the index,\n",
    "\n",
    "ytrain after  \n",
    "[[0. 1. 0. ... 0. 0. 0.]  \n",
    " [1. 0. 0. ... 0. 0. 0.]  \n",
    " [0. 1. 0. ... 0. 0. 0.]  \n",
    " ...  \n",
    " [0. 0. 0. ... 1. 0. 0.]  \n",
    " [0. 0. 0. ... 0. 0. 0.]  \n",
    " [0. 0. 0. ... 0. 0. 1.]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "508a23dfec7dde6ea68e2904277687283a956327",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "print(type(ytrain))\n",
    "# number of classes, in this case 10\n",
    "nclasses = ytrain.max() - ytrain.min() + 1\n",
    "\n",
    "print(\"Shape of ytrain before: \", ytrain.shape) # (42000,)\n",
    "\n",
    "ytrain = to_categorical(ytrain, num_classes = nclasses)\n",
    "\n",
    "print(\"Shape of ytrain after: \", ytrain.shape) # (42000, 10), also numpy.ndarray type\n",
    "print(type(ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e078f5545f1387ae0b49f14fee7ac1d47e5bcae"
   },
   "source": [
    "## 1.9. Split training and validation sets\n",
    "\n",
    "The available data is 42k images. If the NN is trained with these 42k images, it might overfit and respond poorly to new data. Overfitting means that the NN doesn't generalize for the digits, it just learns the differences in those 42k images. When faced with new digits slightly different, the performance decreases considerably. This is not a good outcome, since the goal of the NN is to learn from the training set digits so that it does well on the **new digits**.\n",
    "\n",
    "In order to avoid submitting the predictions and risking a bad performance, and to determine whether the NN overfits, a small percentage of the train data is separated and named validation data. The ratio of the split can vary from 10% in small datasets to 1% in cases with 1M images.\n",
    "\n",
    "The NN is then trained with the remaining of the training data, and in each step/epoch, the NN is tested against the validation data and we can see its performance. That way we can watch how the loss and accuracy metrics vary during training, and in the end determine where there is overfitting and take action (more on this later). For example, the results I had after the 20th epoch with a certain CNN architecture which turned out to overfit:\n",
    "\n",
    "> loss: 0.0066 - acc: 0.9980 - val_loss: 0.0291 - val_acc: 0.9940\n",
    "\n",
    "In this example and without getting much into detail, the __training loss__ is very low while the __val_loss__ is 4 times higher, and the __training accuracy__ is a little higher than the __val_acc__. The accuracy difference is not that much, partly because we are talking about 0.998 vs 0.994, which is exceptionally high, but the difference in loss suggests an overfitting problem.\n",
    "\n",
    "Coming back to the general idea, the **val_acc** is the important metric. The NN might do very well with trained data but the goal is that the NN learns to generalize other than learning the training data \"by heart\". If the NN does well with val data, it's probable that it generalizes well to a certain extent and it will do well with the test data. (more on this in section 2 regarding CNNs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__random_state__ in train_test_split ensures that the data is pseudo-randomly divided.  \n",
    "If the images were ordered by class, activating this feature guarantees their pseudo-random split.  \n",
    "The seed means that every time this pseudo-randomization is applied, the distribution is the same.\n",
    "\n",
    "__stratify__ in train_test_split ensures that there is no overrepresentation of classes in the val set.  \n",
    "It is used to avoid some labels being overrepresented in the val set.   \n",
    "> Note: only works with sklearn version > 0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "117f9749a1511c0a238a0dece0f684bd27b41cef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 2\n",
    "np.random.seed(seed)\n",
    "\n",
    "# percentage of xtrain which will be xval\n",
    "split_pct = 0.1\n",
    "\n",
    "# Split the train and the validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain,\n",
    "                                              ytrain, \n",
    "                                              test_size=split_pct,\n",
    "                                              random_state=seed,\n",
    "                                              stratify=ytrain\n",
    "                                             )\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xval.shape)\n",
    "print(yval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "237545703337e0e18dc1a7f40daa9edff5d9dec3"
   },
   "source": [
    "> Summary\n",
    "\n",
    "The available data is now divided as follows:\n",
    "* **Train data**: images (xtrain) and labels (ytrain), 90% of the available data\n",
    "* **Validation data**: images (xval) and labels (yval), 10% of the available data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6f751f76f859c7b51b846f81dc79baa7609e934"
   },
   "source": [
    "# 2. CNN\n",
    "\n",
    "In this section the CNN is defined, including architecture, optimizers, metrics, learning rate reductions, data augmentation... Then it is compiled and fit to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "162a9388b958cf25272870d290a616be47fd85ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# for the architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPool2D, AvgPool2D\n",
    "\n",
    "# optimizer, data generator and learning rate reductor\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ee343a11f8881814ba57a48bdf1a69752c7cc34"
   },
   "source": [
    "## 2.1. Define model architecture\n",
    "\n",
    "My final CNN architechture is:\n",
    "> In &rarr; [ [Conv2D &rarr; relu]\\*2 &rarr; MaxPool2D &rarr; Dropout ]\\*2 &rarr; Flatten &rarr; Dense &rarr; Dropout &rarr; Out\n",
    "\n",
    "I'd like to encourage everyone who wants to learn about CNNs to begin with a simpler one, such as\n",
    "\n",
    "> In &rarr; [Conv2D &rarr; relu] &rarr; MaxPool2D &rarr; Dropout &rarr; Flatten &rarr; Dense &rarr; Dropout &rarr; Out\n",
    "\n",
    ", check the performance and keep adding layers or tweaking the parameters until you reach an architecture (that may or may not be like mine) with a __val_acc__ of 0.996 more or less, trying to improve that takes much more time and it's really about the details, but of course feel free to try it out. I just encourage that you build your own model and do your own tests, instead of looking at an already well-performing model and using that.\n",
    "\n",
    "In my case I started with the simple architecture, kept a log where I wrote down the loss and accuracy results, changed one thing at a time, checked performance and how it changed with the previous version, wrote down the changes I had made and how the result changed, and made further changes based on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture layers\n",
    "\n",
    "You can read about the theory of CNNs in the Internet from people more knowledgeable than me and who surely explain it much better. So I will skip the theory explanation for the Conv2D, MaxPool2D, Flatten and Dense layers and I will focus on smaller details.\n",
    "\n",
    "   * Conv2D\n",
    "   \n",
    "      * __filters__: usually on the first convolutional layers there are less filters, and more deeper down the CNN. Usually a power of 2 is set, and in this case 16 offered poorer performance and I didn't want to make a big CNN with 64 or 128 filters for digit classification.\n",
    "      \n",
    "      * __kernel_size__: this is the filter size, usually (3,3) or (5,5) is set. I advise setting one, building the architecture and changing it to see if it affects the performance though it usually doesn't.\n",
    "      \n",
    "      * __padding__: two options\n",
    "      \n",
    "         * valid padding: no padding, the image shrinks: n - f + 1\n",
    "         * same padding: padding of 2, the image doesn't shrink: p = (f-1)/2 &rarr; (n+2) - f(=3) + 1 = n\n",
    "         \n",
    "      * __activation__: ReLU is represented mathematically by max(0,X) and offers good performance in CNNs (source: the Internet)\n",
    "\n",
    "\n",
    "   * MaxPool2D: goal is to reduce variance/overfitting and reduce computational complexity since it makes the image smaller. two pooling options\n",
    "   \n",
    "      * MaxPool2D: extracts the most important features like edges\n",
    "      * AvgPool2D: extracts smooth features\n",
    "      \n",
    "      My personal conclusion then is that for binarized images, with noticeable edges, MaxPool performs better.\n",
    "      \n",
    "      \n",
    "   * Dropout: you can read the theory on the Internet, it's a useful tool to reduce overfitting. The net becomes less sensitive to the specific weights of neurons and is more capable of better generalization and less likely to overfit the train data. The optimal dropout value in Conv layers is 0.2 (https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5), and if you want to implement it in the dense layers, its optimal value is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "bb1b773c6bf7baf33756dd265f3a2c1bc662b220"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a4b049e6c0a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dim' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(dim,dim,1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu',))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(nclasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7983fec4500a27ff54adc40535405ba71e9fd80a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5785f24f35271268d9616e45cdde37ddf4547921",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8cb57a110e90a1006995534819c581c16a7b645c"
   },
   "source": [
    "We have used categorical_crossentropy as the cost function for that model but what does we mean by cost function\n",
    "\n",
    "Cost function : It is a measure of the overall loss in our network after assigning values to the parameters during the forward phase so it indicates how well the parameters were chosen during the forward probagation phase.\n",
    "Optimizer : It is the gradiant descent algorithm that is used. We use it to minimize the cost function to approach the minimum point. We are using adam optimizer which is one of the best gradient descent algorithms. You can refere to this paper to know how it works https://arxiv.org/abs/1412.6980v8\n",
    "You can use other metrics to measure the performance other than accuracy as precision or recall or F1 score. the choice depends on the problem itself. Where high recall means low number of false negatives , High precision means low number of false positives and F1 score is a trade off between them. You can refere to this article for more about precision and recall http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "\n",
    "(from coursera audio) However, accuracy isn't a great metric for this task, since the labels are heavily skewed to 0's, so a neural network that just outputs 0's would get slightly over 90% accuracy. We could define more useful metrics such as F1 score or Precision/Recall. But let's not bother with that here, and instead just empirically see how the model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8a38a240404358164f63020aceb591c3907ffdc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2fd7356e907ad7001a84890191271f59975ff49e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec0fa1f7edbfd1c834725c4225c485a1cb13b1c8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1da40a349de35f1c2d4ce96c61c81d0091efc23",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1379cb5bd05278c3726b39df441a5eb1dcd9dc5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5b3c58b2564bdc98ef8f7f949c164ec95b5e876",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a87fb83b3d6654ee0b2a54e65a8b9c00ec48cf4",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(xtrain,ytrain, batch_size=batch_size),\n",
    "                              epochs=epochs, validation_data=(xval,yval),\n",
    "                              verbose=1, steps_per_epoch=xtrain.shape[0]//batch_size, \n",
    "                              callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5876a7e97bfb916020e9c04a6a6056bc96f98669",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "# overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63a0bda9010ac311a6a9c845343c64ebcba8ddc3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "ypred = model.predict(xval)\n",
    "# Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\n",
    "ypred_classes = np.argmax(ypred,axis=1)\n",
    "# Convert validation observations from one hot vectors to labels\n",
    "ytrue = np.argmax(yval,axis=1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(ytrue, ypred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes=range(nclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "242868c9a91318dd86b2222483eaddc09c7b08e8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conf matrix opt2\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(features, labels, test_size=0.1)\n",
    "predicted = np.argmax(model.predict_generator(test_generator(X_validate), steps=X_validate.shape[0]), axis=1)\n",
    "tmp = pd.DataFrame(sklearn.metrics.confusion_matrix(y_validate, predicted))\n",
    "plt.subplots(figsize=(10,10)) \n",
    "sns.heatmap(tmp, annot=True, fmt='.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f5f8df7abc5d6278caa4098f5d39ea7566a55ccb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (ypred_classes - ytrue != 0) # array of bools where the equality is true or false \n",
    "\n",
    "ypred_er = ypred[errors]\n",
    "ypred_classes_er = ypred_classes[errors]\n",
    "ytrue_er = ytrue[errors]\n",
    "xval_er = xval[errors]\n",
    "\n",
    "def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "            \n",
    "# Probabilities of the wrong predicted numbers\n",
    "ypred_er_prob = np.max(ypred_er,axis=1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_er = np.diagonal(np.take(ypred_er, ytrue_er, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_er = ypred_er_prob - true_prob_er\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_delta_er = np.argsort(delta_pred_true_er)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_er = sorted_delta_er[-12:-6]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_er, xval_er, ypred_classes_er, ytrue_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f85a38f96f2fb9c26119f6a2a32ce84ee0751c91",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(test, verbose=1)\n",
    "\n",
    "submissions = pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"mnist0208.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36e50badf8a5683d1e567de0bca4fbe5ab14441c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
