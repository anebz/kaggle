{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport re\nimport string\n\nimport numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport nltk\nfrom nltk.corpus import stopwords",
      "execution_count": 121,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "840823a08129998ba6ddc592f6e8e59aee0e2bac"
      },
      "cell_type": "code",
      "source": "!ls ../input/\n\nprint(\"\\nEmbeddings:\")\n!ls ../input/embeddings/",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": "embeddings  sample_submission.csv  test.csv  train.csv\n\nEmbeddings:\nGoogleNews-vectors-negative300\tparagram_300_sl999\nglove.840B.300d\t\t\twiki-news-300d-1M\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ef138e7bedeeee43de5dc4e129141a4f81cb5b61"
      },
      "cell_type": "markdown",
      "source": "### Embeddings\n\n* GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n* glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n* paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n* wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "577e8d3b18c3b4da618571995f96196651b6f9de"
      },
      "cell_type": "code",
      "source": "print('File sizes')\nfor f in os.listdir('../input'):\n    if 'zip' not in f:\n        print(f.ljust(30) + str(round(os.path.getsize('../input/' + f) / 1000000, 2)) + 'MB')",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": "File sizes\nembeddings                    0.0MB\ntrain.csv                     124.21MB\nsample_submission.csv         1.3MB\ntest.csv                      5.24MB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e5d945c93793073b68cb4b77ed6da5815ea0baf0"
      },
      "cell_type": "markdown",
      "source": "## Open trainset and testset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "866b5d46465241b6a005abadfbf75bc3b200a536"
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv').fillna(' ')\ntest = pd.read_csv('../input/test.csv').fillna(' ')",
      "execution_count": 124,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91131a1a244a09431e0277071855507885f8dae3"
      },
      "cell_type": "code",
      "source": "print(\"Shape of training set: \", train.shape)\nprint(\"Shape of test set: \", test.shape)\n\ntrain_target = train['target'].values\nnp.unique(train_target)\nprint(\"\\nPercentage of insincere questions irt sincere questions: \", train_target.mean(), \"%\")",
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Shape of training set:  (1306122, 3)\nShape of test set:  (56370, 2)\n\nPercentage of insincere questions irt sincere questions:  0.06187017751787352 %\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6fbf6edf551d9306e200de105e07c7cde8698e7c"
      },
      "cell_type": "code",
      "source": "train.sample(10)",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 126,
          "data": {
            "text/plain": "                          qid  ...   target\n389534   4c4d6e8493a31d716982  ...        1\n587338   730ff7afe32ab58b6f76  ...        0\n806507   9e06a27c8a3faebec111  ...        0\n14448    02d77c5461f6e0038d84  ...        0\n922157   b4b33551e461d05964e4  ...        0\n545974   6af5ff7ff384af217886  ...        0\n1245158  f403535631b8b8c102ca  ...        0\n468409   5bba65fd4720f44c08e1  ...        0\n1154072  e22127b57aed745e6d76  ...        0\n1011298  c62b0db4eb48496388be  ...        0\n\n[10 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>389534</th>\n      <td>4c4d6e8493a31d716982</td>\n      <td>What is it in the psyche of those trump suppor...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>587338</th>\n      <td>730ff7afe32ab58b6f76</td>\n      <td>Do you feel that this country has a good leade...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806507</th>\n      <td>9e06a27c8a3faebec111</td>\n      <td>What are the certification courses available i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14448</th>\n      <td>02d77c5461f6e0038d84</td>\n      <td>Why should we consume protein when we wake up?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>922157</th>\n      <td>b4b33551e461d05964e4</td>\n      <td>Is touching the interaction of electric fields...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>545974</th>\n      <td>6af5ff7ff384af217886</td>\n      <td>What's the point for a cake shop to have 'sale...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1245158</th>\n      <td>f403535631b8b8c102ca</td>\n      <td>I am 12. Is it considered toxic if my parent y...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>468409</th>\n      <td>5bba65fd4720f44c08e1</td>\n      <td>If I ask my brother to help me move my heavy f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1154072</th>\n      <td>e22127b57aed745e6d76</td>\n      <td>Can you describe the three phases of post-affa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1011298</th>\n      <td>c62b0db4eb48496388be</td>\n      <td>How do I get the latest technology especially ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce4749543a5d2ff25e62aebfae1b798fb71da3f2"
      },
      "cell_type": "code",
      "source": "test.sample(10)",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 127,
          "data": {
            "text/plain": "                        qid                                      question_text\n22417  656be261fce128fc33cf  Which is the best smartphone between Moto and ...\n11098  32b702c0bcd87930a503  Do gun control advocates usually do not unders...\n33641  97a0d5e2bf5e57f9e1a7  What are some psychological triggers that caus...\n4765   15cc947dd40470ce4afc  Are Chinese software developers become dominan...\n10274  2f2e3952fbeed9e8aed3              What will happen we drink dog’s milk?\n9387   2b40a650c6d7151abb86  Are girls allowed in boys hostel at PICT Pune ...\n5012   16fcc807311628b570b2  What are my chances of getting a fully-funded ...\n363    01c14e356cbb82800f60  Which entity does love Jerusalem more? Israel ...\n34761  9caa0548b60aff101e45       Can you suggest a name for my personal blog?\n49849  e1ff3fe2cf10730ca4db  What is an adduct? How is stability of adduct ...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22417</th>\n      <td>656be261fce128fc33cf</td>\n      <td>Which is the best smartphone between Moto and ...</td>\n    </tr>\n    <tr>\n      <th>11098</th>\n      <td>32b702c0bcd87930a503</td>\n      <td>Do gun control advocates usually do not unders...</td>\n    </tr>\n    <tr>\n      <th>33641</th>\n      <td>97a0d5e2bf5e57f9e1a7</td>\n      <td>What are some psychological triggers that caus...</td>\n    </tr>\n    <tr>\n      <th>4765</th>\n      <td>15cc947dd40470ce4afc</td>\n      <td>Are Chinese software developers become dominan...</td>\n    </tr>\n    <tr>\n      <th>10274</th>\n      <td>2f2e3952fbeed9e8aed3</td>\n      <td>What will happen we drink dog’s milk?</td>\n    </tr>\n    <tr>\n      <th>9387</th>\n      <td>2b40a650c6d7151abb86</td>\n      <td>Are girls allowed in boys hostel at PICT Pune ...</td>\n    </tr>\n    <tr>\n      <th>5012</th>\n      <td>16fcc807311628b570b2</td>\n      <td>What are my chances of getting a fully-funded ...</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>01c14e356cbb82800f60</td>\n      <td>Which entity does love Jerusalem more? Israel ...</td>\n    </tr>\n    <tr>\n      <th>34761</th>\n      <td>9caa0548b60aff101e45</td>\n      <td>Can you suggest a name for my personal blog?</td>\n    </tr>\n    <tr>\n      <th>49849</th>\n      <td>e1ff3fe2cf10730ca4db</td>\n      <td>What is an adduct? How is stability of adduct ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1bf6db5561456aff8964e54954b438b2e75635a"
      },
      "cell_type": "code",
      "source": "insincere_q = train[train[\"target\"] == 1][\"question_text\"].tolist()\n\nwith open('insinceres.txt', 'w') as f:\n    for item in insincere_q:\n        f.write(\"%s\\n\" % item)",
      "execution_count": 128,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c88df5e3870b430000f142be5335ef44fb5c0bc6"
      },
      "cell_type": "markdown",
      "source": "## N-gram analysis\n\n#### 1-gram analysis"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f8977442c6e6b52d5c11e781b324b7d6f87e3892"
      },
      "cell_type": "code",
      "source": "from collections import defaultdict\nfrom wordcloud import STOPWORDS\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\ninsinc_df = train[train.target==1]\nsinc_df = train[train.target==0]\n\ndef plot_ngrams(n_grams):\n\n    ## custom function for ngram generation ##\n    def generate_ngrams(text, n_gram=1):\n        token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n        ngrams = zip(*[token[i:] for i in range(n_gram)])\n        return [\" \".join(ngram) for ngram in ngrams]\n\n    ## custom function for horizontal bar chart ##\n    def horizontal_bar_chart(df, color):\n        trace = go.Bar(\n            y=df[\"word\"].values[::-1],\n            x=df[\"wordcount\"].values[::-1],\n            showlegend=False,\n            orientation = 'h',\n            marker=dict(\n                color=color,\n            ),\n        )\n        return trace\n\n    def get_bar(df, bar_color):\n        freq_dict = defaultdict(int)\n        for sent in df[\"question_text\"]:\n            for word in generate_ngrams(sent, n_grams):\n                freq_dict[word] += 1\n        fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n        fd_sorted.columns = [\"word\", \"wordcount\"]\n        trace = horizontal_bar_chart(fd_sorted.head(10), bar_color)\n        return trace    \n\n    trace0 = get_bar(sinc_df, 'blue')\n    trace1 = get_bar(insinc_df, 'blue')\n\n    # Creating two subplots\n    if n_grams == 1:\n        wrd = \"words\"\n    elif n_grams == 2:\n        wrd = \"bigrams\"\n    elif n_grams == 3:\n        wrd = \"trigrams\"\n    \n    fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,\n                              subplot_titles=[\"Frequent \" + wrd + \" of sincere questions\", \n                                              \"Frequent \" + wrd + \" of insincere questions\"])\n    fig.append_trace(trace0, 1, 1)\n    fig.append_trace(trace1, 1, 2)\n    fig['layout'].update(height=500, width=1150, paper_bgcolor='rgb(233,233,233)', title=wrd + \" Count Plots\")\n    py.iplot(fig, filename='word-plots')\n",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>",
            "text/vnd.plotly.v1+html": "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11aefca40f1be0894aff64cd432f7c948514d225"
      },
      "cell_type": "code",
      "source": "plot_ngrams(1)",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": "This is the format of your plot grid:\n[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.plotly.v1+json": {
              "data": [
                {
                  "marker": {
                    "color": "blue"
                  },
                  "orientation": "h",
                  "showlegend": false,
                  "x": [
                    19728,
                    20108,
                    20788,
                    21641,
                    25696,
                    28840,
                    34827,
                    37960,
                    45675,
                    60816
                  ],
                  "y": [
                    "someone",
                    "much",
                    "many",
                    "think",
                    "make",
                    "one",
                    "good",
                    "people",
                    "will",
                    "best"
                  ],
                  "type": "bar",
                  "uid": "d3633403-5d60-4b2a-a9fa-48e94d427566",
                  "xaxis": "x",
                  "yaxis": "y"
                },
                {
                  "marker": {
                    "color": "blue"
                  },
                  "orientation": "h",
                  "showlegend": false,
                  "x": [
                    2828,
                    2984,
                    3152,
                    3351,
                    3552,
                    3774,
                    4590,
                    4757,
                    4893,
                    11036
                  ],
                  "y": [
                    "muslims",
                    "indian",
                    "men",
                    "white",
                    "many",
                    "think",
                    "will",
                    "women",
                    "trump",
                    "people"
                  ],
                  "type": "bar",
                  "uid": "0ae6f17d-c93f-46b0-928e-9333844fb6e4",
                  "xaxis": "x2",
                  "yaxis": "y2"
                }
              ],
              "layout": {
                "annotations": [
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Frequent words of sincere questions",
                    "x": 0.225,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  },
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Frequent words of insincere questions",
                    "x": 0.775,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  }
                ],
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    0.45
                  ]
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ]
                },
                "xaxis2": {
                  "anchor": "y2",
                  "domain": [
                    0.55,
                    1
                  ]
                },
                "yaxis2": {
                  "anchor": "x2",
                  "domain": [
                    0,
                    1
                  ]
                },
                "height": 500,
                "width": 1150,
                "paper_bgcolor": "rgb(233,233,233)",
                "title": "words Count Plots"
              },
              "config": {
                "showLink": true,
                "linkText": "Export to plot.ly",
                "plotlyServerURL": "https://plot.ly"
              }
            },
            "text/html": "<div id=\"418857da-cfe1-4982-91ab-a553641757d7\" style=\"height: 500px; width: 1150px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"418857da-cfe1-4982-91ab-a553641757d7\", [{\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [19728, 20108, 20788, 21641, 25696, 28840, 34827, 37960, 45675, 60816], \"y\": [\"someone\", \"much\", \"many\", \"think\", \"make\", \"one\", \"good\", \"people\", \"will\", \"best\"], \"type\": \"bar\", \"uid\": \"d3633403-5d60-4b2a-a9fa-48e94d427566\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [2828, 2984, 3152, 3351, 3552, 3774, 4590, 4757, 4893, 11036], \"y\": [\"muslims\", \"indian\", \"men\", \"white\", \"many\", \"think\", \"will\", \"women\", \"trump\", \"people\"], \"type\": \"bar\", \"uid\": \"0ae6f17d-c93f-46b0-928e-9333844fb6e4\", \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of sincere questions\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of insincere questions\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"height\": 500, \"width\": 1150, \"paper_bgcolor\": \"rgb(233,233,233)\", \"title\": \"words Count Plots\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script>",
            "text/vnd.plotly.v1+html": "<div id=\"418857da-cfe1-4982-91ab-a553641757d7\" style=\"height: 500px; width: 1150px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"418857da-cfe1-4982-91ab-a553641757d7\", [{\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [19728, 20108, 20788, 21641, 25696, 28840, 34827, 37960, 45675, 60816], \"y\": [\"someone\", \"much\", \"many\", \"think\", \"make\", \"one\", \"good\", \"people\", \"will\", \"best\"], \"type\": \"bar\", \"uid\": \"d3633403-5d60-4b2a-a9fa-48e94d427566\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [2828, 2984, 3152, 3351, 3552, 3774, 4590, 4757, 4893, 11036], \"y\": [\"muslims\", \"indian\", \"men\", \"white\", \"many\", \"think\", \"will\", \"women\", \"trump\", \"people\"], \"type\": \"bar\", \"uid\": \"0ae6f17d-c93f-46b0-928e-9333844fb6e4\", \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of sincere questions\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of insincere questions\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"height\": 500, \"width\": 1150, \"paper_bgcolor\": \"rgb(233,233,233)\", \"title\": \"words Count Plots\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a611fa3718b5d0ad341d7fef4e9d185730474659"
      },
      "cell_type": "code",
      "source": "plot_ngrams(2)",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": "This is the format of your plot grid:\n[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.plotly.v1+json": {
              "data": [
                {
                  "marker": {
                    "color": "blue"
                  },
                  "orientation": "h",
                  "showlegend": false,
                  "x": [
                    1775,
                    1796,
                    1797,
                    1822,
                    1859,
                    1870,
                    1931,
                    2084,
                    2972,
                    6973
                  ],
                  "y": [
                    "high school",
                    "long take",
                    "united states",
                    "known for?",
                    "even though",
                    "computer science",
                    "many people",
                    "will happen",
                    "year old",
                    "best way"
                  ],
                  "type": "bar",
                  "uid": "42eb109d-6a44-459e-93ab-6341d6bca5a6",
                  "xaxis": "x",
                  "yaxis": "y"
                },
                {
                  "marker": {
                    "color": "blue"
                  },
                  "orientation": "h",
                  "showlegend": false,
                  "x": [
                    305,
                    328,
                    330,
                    335,
                    335,
                    360,
                    383,
                    653,
                    673,
                    1076
                  ],
                  "y": [
                    "hillary clinton",
                    "president trump",
                    "year old",
                    "trump supporters",
                    "even though",
                    "united states",
                    "many people",
                    "black people",
                    "white people",
                    "donald trump"
                  ],
                  "type": "bar",
                  "uid": "39e54669-ada0-48d3-8f07-cb00a295ec65",
                  "xaxis": "x2",
                  "yaxis": "y2"
                }
              ],
              "layout": {
                "annotations": [
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Frequent bigrams of sincere questions",
                    "x": 0.225,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  },
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Frequent bigrams of insincere questions",
                    "x": 0.775,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  }
                ],
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    0.45
                  ]
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ]
                },
                "xaxis2": {
                  "anchor": "y2",
                  "domain": [
                    0.55,
                    1
                  ]
                },
                "yaxis2": {
                  "anchor": "x2",
                  "domain": [
                    0,
                    1
                  ]
                },
                "height": 500,
                "width": 1150,
                "paper_bgcolor": "rgb(233,233,233)",
                "title": "bigrams Count Plots"
              },
              "config": {
                "showLink": true,
                "linkText": "Export to plot.ly",
                "plotlyServerURL": "https://plot.ly"
              }
            },
            "text/html": "<div id=\"72a9d999-2376-40ef-a1e1-a31c339c4c35\" style=\"height: 500px; width: 1150px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"72a9d999-2376-40ef-a1e1-a31c339c4c35\", [{\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [1775, 1796, 1797, 1822, 1859, 1870, 1931, 2084, 2972, 6973], \"y\": [\"high school\", \"long take\", \"united states\", \"known for?\", \"even though\", \"computer science\", \"many people\", \"will happen\", \"year old\", \"best way\"], \"type\": \"bar\", \"uid\": \"42eb109d-6a44-459e-93ab-6341d6bca5a6\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [305, 328, 330, 335, 335, 360, 383, 653, 673, 1076], \"y\": [\"hillary clinton\", \"president trump\", \"year old\", \"trump supporters\", \"even though\", \"united states\", \"many people\", \"black people\", \"white people\", \"donald trump\"], \"type\": \"bar\", \"uid\": \"39e54669-ada0-48d3-8f07-cb00a295ec65\", \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent bigrams of sincere questions\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent bigrams of insincere questions\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"height\": 500, \"width\": 1150, \"paper_bgcolor\": \"rgb(233,233,233)\", \"title\": \"bigrams Count Plots\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script>",
            "text/vnd.plotly.v1+html": "<div id=\"72a9d999-2376-40ef-a1e1-a31c339c4c35\" style=\"height: 500px; width: 1150px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"72a9d999-2376-40ef-a1e1-a31c339c4c35\", [{\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [1775, 1796, 1797, 1822, 1859, 1870, 1931, 2084, 2972, 6973], \"y\": [\"high school\", \"long take\", \"united states\", \"known for?\", \"even though\", \"computer science\", \"many people\", \"will happen\", \"year old\", \"best way\"], \"type\": \"bar\", \"uid\": \"42eb109d-6a44-459e-93ab-6341d6bca5a6\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [305, 328, 330, 335, 335, 360, 383, 653, 673, 1076], \"y\": [\"hillary clinton\", \"president trump\", \"year old\", \"trump supporters\", \"even though\", \"united states\", \"many people\", \"black people\", \"white people\", \"donald trump\"], \"type\": \"bar\", \"uid\": \"39e54669-ada0-48d3-8f07-cb00a295ec65\", \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent bigrams of sincere questions\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent bigrams of insincere questions\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"height\": 500, \"width\": 1150, \"paper_bgcolor\": \"rgb(233,233,233)\", \"title\": \"bigrams Count Plots\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3bd837725f0c58e64a8fa719f9591298586b9e9f"
      },
      "cell_type": "code",
      "source": "plot_ngrams(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1318207a8bc57c8d3eb7f4912c483347935f4e2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5b77a6419823d8d9f623e852257ac998fc806da7"
      },
      "cell_type": "markdown",
      "source": "## EDA observations\n\n### 1. Mean word length is quite different\nmean_word_len in train 57.6  \nmean_word_len in test 29.3\n\n### 2. Num words, testset has more variance\n![image.png](attachment:image.png)\n\n### 3. [Quora source](https://www.quora.com/What-is-an-insincere-question)\n\nPossible words in insincere questions:  \n* why (maybe also what,how)\n* so\n* such\n* finally\n* than"
    },
    {
      "metadata": {
        "_uuid": "7504e1c41816c9c9cd90600e86bfe95937d66edd"
      },
      "cell_type": "markdown",
      "source": "# Resources from other competitions\n\n[Discussion post](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/70788) (see comments and most upvoted kernels from the competitions) \n\n* [Toxic comment classification challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)  (see most upvoted kernels)\n* [Example of rheoterical questions](http://examples.yourdictionary.com/rhetorical-question-examples.html)\n\n## Kernels\n\n#### Introductory EDA\n* https://www.kaggle.com/thebrownviking20/analyzing-quora-for-the-insinceres\n* [Very general EDA](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora) already went through it\n* [A look at different embeddings](https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings)\n* [LSTM and embeddings](https://www.kaggle.com/mihaskalic/lstm-is-all-you-need-well-maybe-embeddings-also)\n* [Toxic comments EDA](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\n* [Toxic using keras](https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras)\n* [Do pretrained embeddings help?](https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge)\n* [Miscellaneous helping material](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71361) (more in comments)\n* [Preprocess when using embeddings](https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings)\n* [EDA for another Quora competition](https://www.kaggle.com/philschmidt/quora-eda-model-selection-roc-pr-plots)\n* [EDA from indian (very well explained)](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) went through it\n* [EDA and LSTM-CNN](https://www.kaggle.com/artgor/eda-and-lstm-cnn)\n* [Simple EDA](https://www.kaggle.com/tunguz/just-some-simple-eda) went through it\n\n\n#### Other\n* [Augmentation for text](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71083)\n* [Papers for text classification](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/70821)\n* [Strange sentences marked as insincere](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/70956)\n* [General advice on kaggle competitions](https://www.kaggle.com/c/PLAsTiCC-2018/discussion/70908)\n* [Embeddings with attention](https://www.kaggle.com/shujian/different-embeddings-with-attention-fork-fork)\n* [Text pre-processing techniques](https://www.kaggle.com/deffro/text-pre-processing-techniques)\n* [Importance of cleaning text](https://www.kaggle.com/currie32/the-importance-of-cleaning-text)\n* [Blendingis all you need](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/72627)\n* [Text preprocessing](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing)\n* [Methods to combine embeddings](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)\n* [Material for beginners, toxic comment classification](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71361)\n* [Analyzing Quora for insinceres](https://www.kaggle.com/thebrownviking20/analyzing-quora-for-the-insinceres)"
    },
    {
      "metadata": {
        "_uuid": "3e176b44bf97849cb641da3b086da81c16849031"
      },
      "cell_type": "markdown",
      "source": "## Create hyperparameters\n\n* Average length of the words"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9bef6bd2c53eb5f058195ca279c533d875e1d074"
      },
      "cell_type": "code",
      "source": "## https://www.kaggle.com/tunguz/just-some-simple-eda\neng_stopwords = set(stopwords.words(\"english\"))\n\n## Average length of the words in the text \ntrain[\"mean_word_len\"] = train[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ntest[\"mean_word_len\"] = test[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "3fa7c2b5998f9f0297a05fde5fedfa04455b6e68"
      },
      "cell_type": "code",
      "source": "print(train.columns)\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41d39abc2c7988252fee8e04f5552c02c0bea850"
      },
      "cell_type": "code",
      "source": "#Remove bad symbols and stopwords from test and train data\nREPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\nBAD_SYMBOLS_RE = re.compile('[^0-9a-zA-Z #+_]')\nSTOPWORDS = set(stopwords.words('english'))\n\ndef text_prepare(text):\n    \"\"\"\n        text: a string\n        return: modified initial string\n    \"\"\"\n    text = text.lower()   # lowercase text\n    text = REPLACE_BY_SPACE_RE.sub(\" \", text)     # replace REPLACE_BY_SPACE_RE symbols by space in text\n    text = BAD_SYMBOLS_RE.sub(\"\", text)     # delete symbols which are in BAD_SYMBOLS_RE from text\n    \n    \n    resultwords = [word for word in text.split() if word not in STOPWORDS]  # delete stopwords from text\n    text = ' '.join(resultwords)\n    \n    return text",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}